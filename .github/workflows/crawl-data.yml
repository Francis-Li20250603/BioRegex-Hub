name: 抓取监管数据

on:
  workflow_dispatch:
  schedule:
    - cron: "0 3 * * 0"  # 每周日凌晨3点自动运行

permissions:
  contents: write   # ✅ 允许 GITHUB_TOKEN 写入

jobs:
  crawl-data:
    runs-on: ubuntu-latest
    steps:
      - name: 拉取代码
        uses: actions/checkout@v4

      - name: 安装Python环境
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: 安装依赖
        working-directory: backend
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          # 确保爬虫必需库存在
          pip install requests beautifulsoup4 lxml pandas openpyxl

      - name: 创建 data 文件夹
        run: mkdir -p backend/data

      - name: 抓取FDA数据
        working-directory: backend
        run: python -m scripts.crawlers.crawl_fda

      - name: 抓取EMA/EFSA数据
        working-directory: backend
        run: python -m scripts.crawlers.crawl_ema_efsa

      - name: 提交并推送抓取的数据
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "chore: update crawled regulatory datasets"
          branch: main
          file_pattern: backend/data/*
          commit_user_name: github-actions[bot]
          commit_user_email: 41898282+github-actions[bot]@users.noreply.github.com



