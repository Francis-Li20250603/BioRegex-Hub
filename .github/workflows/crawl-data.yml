name: 抓取监管数据

on:
  workflow_dispatch:
  schedule:
    - cron: "0 3 * * 0"  # 每周日凌晨3点自动运行

jobs:
  crawl-data:
    runs-on: ubuntu-latest
    steps:
      - name: 拉取代码
        uses: actions/checkout@v4

      - name: 安装Python环境
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: 安装依赖
        working-directory: backend
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: 创建 data 文件夹
        run: mkdir -p backend/data

      - name: 抓取FDA数据
        working-directory: backend
        run: python -m scripts.crawlers.crawl_fda

      - name: 抓取HIPAA数据
        working-directory: backend
        run: python -m scripts.crawlers.crawl_hipaa

      - name: 抓取CMS数据
        working-directory: backend
        run: python -m scripts.crawlers.crawl_cms

      - name: 抓取EMA/EFSA数据
        working-directory: backend
        run: python -m scripts.crawlers.crawl_ema_efsa

      # ✅ Commit crawled data into repo
      - name: 提交并推送抓取的数据
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "chore: update crawled regulatory datasets"
          branch: main
          file_pattern: backend/data/*

