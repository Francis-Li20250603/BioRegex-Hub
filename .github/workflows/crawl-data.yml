name: 数据抓取与更新

on:
  schedule:
    - cron: '0 3 * * 1'   # 每周一 03:00 UTC 抓取
  workflow_dispatch:       # 允许手动触发

jobs:
  crawl-data:
    runs-on: ubuntu-latest
    permissions:
      contents: write   # 允许推送 CSV 到仓库
    steps:
      - name: 拉取代码
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: 安装Python环境
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: 安装依赖
        run: |
          python -m pip install --upgrade pip
          pip install requests beautifulsoup4

      - name: 抓取FDA数据
        working-directory: backend
        run: python -m scripts.crawlers.crawl_fda

      - name: 抓取HIPAA数据
        working-directory: backend
        run: python -m scripts.crawlers.crawl_hipaa

      - name: 抓取CMS数据
        working-directory: backend
        run: python -m scripts.crawlers.crawl_cms

      - name: 抓取EMA/EFSA数据
        working-directory: backend
        run: python -m scripts.crawlers.crawl_ema_efsa

      - name: 提交数据到仓库
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "data: update crawled regulatory datasets"
          file_pattern: data/*.csv
          branch: main
